{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7048a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "llm=GoogleGenerativeAI(model=\"gemini-1.5-flash\", max_output_tokens=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b778eb",
   "metadata": {},
   "source": [
    "### PromptsTemplate in langchain <br> Templates with Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6663ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt type: <class 'langchain_core.prompts.prompt.PromptTemplate'>\n",
      "inptut variables: ['age', 'name']\n",
      "hey my name is ujwal and I am 22 years old\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "tempalte=\"hey my name is {name} and I am {age} years old\"\n",
    "prompt=PromptTemplate.from_template(tempalte)\n",
    "\n",
    "print(\"prompt type:\", type(prompt))\n",
    "print(\"inptut variables:\", prompt.input_variables)\n",
    "print(prompt.format(name=\"james\", age=22))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5233add2",
   "metadata": {},
   "source": [
    "### Partial Prompts to define some Default var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8e9be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey my name is ujwal and I am 22 years old and I am a developer\n"
     ]
    }
   ],
   "source": [
    "tempalte=\"hey my name is {name} and I am {age} years old and I am a {profession}\"\n",
    "prompt=PromptTemplate.from_template(tempalte)\n",
    "\n",
    "prompt_with_default=prompt.partial(name=\"james\", age=22)\n",
    "\n",
    "#now provide only the profession\n",
    "print(prompt_with_default.format(profession=\"developer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19791ec1",
   "metadata": {},
   "source": [
    "### Template with the multiple messages of CHAT models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed45cb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are a helpful assistant\n",
      "Human: What is LangChain?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate\n",
    "\n",
    "chat_tempalte = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\"You are a helpful assistant\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{question}\"),\n",
    "])\n",
    "chat=chat_tempalte.partial(question=\"What is LangChain?\")\n",
    "print(chat.format())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77c7c7f",
   "metadata": {},
   "source": [
    "### Few Shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9803bae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are a helpful assistant\n",
      "Human: What is LangChain?\n",
      "AI: LangChain is a framework for building applications with LLMs.\n",
      "Human: What is LangGraph?\n",
      "AI: LangGraph is a framework\n",
      "Human: What is LangGraph?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate\n",
    "\n",
    "exmaple=[\n",
    "    {\"input\": \"What is LangChain?\", \"output\": \"LangChain is a framework for building applications with LLMs.\"},\n",
    "    {\"input\": \"What is LangGraph?\", \"output\": \"LangGraph is a framework\"}\n",
    "]\n",
    "\n",
    "example_prompt=ChatPromptTemplate.from_messages([\n",
    "    HumanMessagePromptTemplate.from_template(\"{input}\"),\n",
    "    AIMessagePromptTemplate.from_template(\"{output}\")\n",
    "    ])\n",
    "few_shot_prompt=FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=exmaple,\n",
    ")\n",
    "final_prompt=ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\"You are a helpful assistant\"),\n",
    "    few_shot_prompt,\n",
    "    HumanMessagePromptTemplate.from_template(\"{input}\")\n",
    "])\n",
    "print(final_prompt.format(input=\"What is LangGraph?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493ca32f",
   "metadata": {},
   "source": [
    "# Output Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a439bba3",
   "metadata": {},
   "source": [
    "### Chains fro using | for chains the prompt must be a Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42232c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response without parser: There are many jokes about lions!  To tell you a good one, I need a little more information. What *kind* of joke are you looking for?  For example:\n",
      "\n",
      "* **A pun?** (e.g.,  What do you call a lazy kangaroo? Pouch potato!  A lion joke could play on words like \"mane\" or \"roar\".)\n",
      "* **A one-liner?** (A short, simple joke.)\n",
      "* **A longer story joke?**\n",
      "* **A joke about a lion's personality?** (e.g.,  a lion being grumpy, regal, etc.)\n",
      "\n",
      "Tell me what style of joke you prefer, and I'll try my best!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt=\"what is the joke about {animal}?\"\n",
    "chat_promt=ChatPromptTemplate.from_template(prompt)\n",
    "chain_no_parser= chat_promt | llm\n",
    "response= chain_no_parser.invoke(chat_promt.format(animal=\"lion\"))\n",
    "print(\"Response without parser:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94bb907e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response with parser: There are many lion jokes!  To tell you one, I need a little more information.  What *kind* of lion joke are you looking for?  For example, are you looking for:\n",
      "\n",
      "* **A pun?** (e.g.,  playing on words related to lions)\n",
      "* **A one-liner?** (a short, quick joke)\n",
      "* **A longer story joke?**\n",
      "* **A joke about a specific aspect of lions?** (e.g., their mane, their roar)\n",
      "\n",
      "\n",
      "Tell me what you'd prefer and I'll do my best!\n"
     ]
    }
   ],
   "source": [
    "chain_parser= chat_promt | llm | StrOutputParser()\n",
    "response_with_parser= chain_parser.invoke({\"animal\": \"lion\"})\n",
    "print(\"Response with parser:\", response_with_parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e05a67",
   "metadata": {},
   "source": [
    "## JSON parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8970433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format instructions for JSON parser: Return a JSON object.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "json_parser = JsonOutputParser()\n",
    "format_instructions=json_parser.get_format_instructions()\n",
    "print(\"Format instructions for JSON parser:\", format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d501bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response with JSON parser: {'name': 'james', 'age': 22}\n",
      "james\n"
     ]
    }
   ],
   "source": [
    "prompt=ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\"You are a helpful assistant\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"extract the name and age from the following text: {text}, {format_instructions}\"),\n",
    "]).partial(\n",
    "    format_instructions=format_instructions\n",
    ")\n",
    "\n",
    "chain_json_parser = prompt | llm | json_parser\n",
    "text=\"My name is james and I am 22 years old.\"\n",
    "response_json_parser = chain_json_parser.invoke({\"text\": text})\n",
    "print(\"Response with JSON parser:\", response_json_parser)\n",
    "print(response_json_parser[\"name\"])  # Accessing the name "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd5a499",
   "metadata": {},
   "source": [
    "## Pydantic Parser<br>for more deailed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d35bff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format instructions for Pydantic parser: The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"animal\": {\"description\": \"The animal the joke is about\", \"title\": \"Animal\", \"type\": \"string\"}, \"joke\": {\"description\": \"The joke itself\", \"title\": \"Joke\", \"type\": \"string\"}}, \"required\": [\"animal\", \"joke\"]}\n",
      "```\n",
      "Response with Pydantic parser: animal='Lion' joke='Why are lions bad dancers? Because they have no mane-ners!'\n",
      "Joke: Why are lions bad dancers? Because they have no mane-ners!\n",
      "Animal: Lion\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    animal: str = Field(description=\"The animal the joke is about\")\n",
    "    joke: str = Field(description=\"The joke itself\")\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "pydantic_parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "\n",
    "format_instructions = pydantic_parser.get_format_instructions()\n",
    "print(\"Format instructions for Pydantic parser:\", format_instructions)\n",
    "\n",
    "promt=ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\"You are a helpful assistant\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"tell me a joke about {animal}, {format_instructions}\"),\n",
    "]).partial(format_instructions=format_instructions)\n",
    "\n",
    "chain = promt | llm | pydantic_parser\n",
    "response = chain.invoke({\"animal\": \"lion\"})\n",
    "print(\"Response with Pydantic parser:\", response)\n",
    "print(\"Joke:\", response.joke)  # Accessing the joke\n",
    "print(\"Animal:\", response.animal)  # Accessing the animal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5272c94a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
