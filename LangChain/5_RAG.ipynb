{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "114ffd92",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation (RAG)<br>\n",
    "<ul>\n",
    "Indexing<ol>\n",
    "Doccument loading<br>\n",
    "Text Splitting<br>\n",
    "Embedding<br>\n",
    "vector storeage<br></ol>\n",
    "Retirval<ol>\n",
    "query embedding<br>\n",
    "Sim search<br>\n",
    "retirve K docc K-means<br>\n",
    "Context augmentation<br></ol>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347959bb",
   "metadata": {},
   "source": [
    "### Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32922617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 documents from text file.\n",
      "metadata: {'source': 'data/text.txt'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders.text import TextLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import os\n",
    "\n",
    "loader= TextLoader(\"data/text.txt\",encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents from text file.\")\n",
    "print(\"metadata:\", documents[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93879948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 documents from PDF file.\n",
      "metadata: {'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': 'Smart Water Bottle Proposal', 'author': 'ChatGPT Canvas', 'source': 'data/pdf.pdf', 'total_pages': 3, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "loader = PyPDFLoader(\"data/pdf.pdf\")\n",
    "documents = loader.load()\n",
    "print(f\"Loaded {len(documents)} documents from PDF file.\")\n",
    "print(\"metadata:\", documents[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdb42347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 documents from web page.\n",
      "metadata: {'source': 'https://en.wikipedia.org/wiki/William_Hanna', 'title': 'William Hanna - Wikipedia', 'language': 'en'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://en.wikipedia.org/wiki/William_Hanna\")\n",
    "documents = loader.load()\n",
    "print(f\"Loaded {len(documents)} documents from web page.\")\n",
    "print(\"metadata:\", documents[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01cd747",
   "metadata": {},
   "source": [
    "### Text splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02fc5e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "long_text = \"\"\"\n",
    "LangChain is a powerful framework for developing applications powered by language models.\n",
    "It enables applications that are:\n",
    "1. Data-aware: connect a language model to other sources of data.\n",
    "2. Agentic: allow a language model to interact with its environment.\n",
    "\n",
    "The core idea of LangChain is to \"chain\" together different components to create more advanced use cases around LLMs.\n",
    "This includes modules for:\n",
    "- Models: LLMs, ChatModels, Embeddings\n",
    "- Prompts: PromptTemplate, ChatPromptTemplate\n",
    "- Output Parsers: StrOutputParser, JsonOutputParser, PydanticOutputParser\n",
    "- Indexes: Document Loaders, Text Splitters, Vectorstores, Retrievers\n",
    "- Chains: Combining components with LCEL\n",
    "- Agents: LLMs that can make decisions and use tools\n",
    "- Memory: Persisting state between turns\n",
    "\n",
    "LangChain is available in Python and JavaScript/TypeScript.\n",
    "It also has related projects like LangServe for deployment and LangSmith for observability.\n",
    "\"\"\"\n",
    "doc_to_split = Document(page_content=long_text, metadata={\"source\": \"internal_doc\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "257441af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split document into 13 chunks:\n",
      "Chunk 1: LangChain is a powerful framework for developing a... (metadata: {'source': 'internal_doc'})\n",
      "Chunk 2: It enables applications that are:\n",
      "1. Data-aware: c... (metadata: {'source': 'internal_doc'})\n",
      "Chunk 3: 2. Agentic: allow a language model to interact wit... (metadata: {'source': 'internal_doc'})\n",
      "Chunk 4: The core idea of LangChain is to \"chain\" together ... (metadata: {'source': 'internal_doc'})\n",
      "Chunk 5: more advanced use cases around LLMs.... (metadata: {'source': 'internal_doc'})\n",
      "Chunk 6: This includes modules for:\n",
      "- Models: LLMs, ChatMod... (metadata: {'source': 'internal_doc'})\n",
      "Chunk 7: - Prompts: PromptTemplate, ChatPromptTemplate... (metadata: {'source': 'internal_doc'})\n",
      "Chunk 8: - Output Parsers: StrOutputParser, JsonOutputParse... (metadata: {'source': 'internal_doc'})\n",
      "Chunk 9: - Indexes: Document Loaders, Text Splitters, Vecto... (metadata: {'source': 'internal_doc'})\n",
      "Chunk 10: - Chains: Combining components with LCEL\n",
      "- Agents:... (metadata: {'source': 'internal_doc'})\n",
      "Chunk 11: - Memory: Persisting state between turns... (metadata: {'source': 'internal_doc'})\n",
      "Chunk 12: LangChain is available in Python and JavaScript/Ty... (metadata: {'source': 'internal_doc'})\n",
      "Chunk 13: It also has related projects like LangServe for de... (metadata: {'source': 'internal_doc'})\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100, chunk_overlap=20,separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents([doc_to_split])\n",
    "\n",
    "print(f\"Split document into {len(chunks)} chunks:\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i+1}: {chunk.page_content[:50]}... (metadata: {chunk.metadata})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8087f577",
   "metadata": {},
   "source": [
    "## Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0549406a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 documents from text file.\n",
      "Chunk 1: Title of the Innovation:Smart Heating and Cooling ... (metadata: {'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': 'Smart Water Bottle Proposal', 'author': 'ChatGPT Canvas', 'source': 'data/pdf.pdf', 'total_pages': 3, 'page': 0, 'page_label': '1'})\n",
      "Chunk 2: Theme:\n",
      "Low carbon footprint solution/Technology... (metadata: {'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': 'Smart Water Bottle Proposal', 'author': 'ChatGPT Canvas', 'source': 'data/pdf.pdf', 'total_pages': 3, 'page': 0, 'page_label': '1'})\n",
      "Chunk 3: Problem Statement :\\ Access to clean and temperatu... (metadata: {'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': 'Smart Water Bottle Proposal', 'author': 'ChatGPT Canvas', 'source': 'data/pdf.pdf', 'total_pages': 3, 'page': 0, 'page_label': '1'})\n",
      "Created vector store with 124 documents.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embedding_model = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=google_api_key)\n",
    "\n",
    "loader = PyPDFLoader(\"data/pdf.pdf\")\n",
    "documents = loader.load()\n",
    "print(f\"Loaded {len(documents)} documents from text file.\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100, chunk_overlap=20,separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "for i in range(3):\n",
    "    print(f\"Chunk {i+1}: {chunks[i].page_content[:50]}... (metadata: {chunks[i].metadata})\")\n",
    "\n",
    "DB=Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")\n",
    "print(f\"Created vector store with {len(DB)} documents.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54043fe7",
   "metadata": {},
   "source": [
    "## Search and Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91a33b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ujwal\\AppData\\Local\\Temp\\ipykernel_14020\\3468238872.py:3: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  print(f\"Created retriever with {retriever.get_relevant_documents('LangChain')}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created retriever with [Document(metadata={'total_pages': 3, 'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'page': 1, 'author': 'ChatGPT Canvas', 'source': 'data/pdf.pdf', 'creationdate': '', 'title': 'Smart Water Bottle Proposal', 'page_label': '2'}, page_content='making it cost-effective'), Document(metadata={'page_label': '2', 'creator': 'ChatGPT', 'total_pages': 3, 'producer': 'WeasyPrint 65.1', 'creationdate': '', 'source': 'data/pdf.pdf', 'author': 'ChatGPT Canvas', 'page': 1, 'title': 'Smart Water Bottle Proposal'}, page_content='dependency  on  a  continuous'), Document(metadata={'producer': 'WeasyPrint 65.1', 'page_label': '2', 'creator': 'ChatGPT', 'title': 'Smart Water Bottle Proposal', 'total_pages': 3, 'author': 'ChatGPT Canvas', 'creationdate': '', 'page': 1, 'source': 'data/pdf.pdf'}, page_content='integration of simple')]\n"
     ]
    }
   ],
   "source": [
    "db_retriever = Chroma(persist_directory=\"./chroma_db\", embedding_function=embedding_model) #load vecore store\n",
    "retriever = db_retriever.as_retriever(search_kwargs={\"k\": 3})\n",
    "print(f\"Created retriever with {retriever.get_relevant_documents('LangChain')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7884bbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Document 1 for query 'who is the information about': way to access... (metadata: {'author': 'ChatGPT Canvas', 'creator': 'ChatGPT', 'source': 'data/pdf.pdf', 'page_label': '1', 'total_pages': 3, 'producer': 'WeasyPrint 65.1', 'page': 0, 'title': 'Smart Water Bottle Proposal', 'creationdate': ''})\n",
      "Retrieved Document 2 for query 'who is the information about': products.... (metadata: {'title': 'Smart Water Bottle Proposal', 'page': 0, 'page_label': '1', 'creator': 'ChatGPT', 'producer': 'WeasyPrint 65.1', 'creationdate': '', 'total_pages': 3, 'source': 'data/pdf.pdf', 'author': 'ChatGPT Canvas'})\n",
      "Retrieved Document 3 for query 'who is the information about': components.... (metadata: {'page_label': '2', 'title': 'Smart Water Bottle Proposal', 'producer': 'WeasyPrint 65.1', 'source': 'data/pdf.pdf', 'creator': 'ChatGPT', 'total_pages': 3, 'author': 'ChatGPT Canvas', 'creationdate': '', 'page': 1})\n",
      "\n",
      "\n",
      "Retrieved Document 1 for query 'what is the lenghts of amazon river': way to access... (metadata: {'creationdate': '', 'total_pages': 3, 'source': 'data/pdf.pdf', 'page_label': '1', 'author': 'ChatGPT Canvas', 'title': 'Smart Water Bottle Proposal', 'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'page': 0})\n",
      "Retrieved Document 2 for query 'what is the lenghts of amazon river': products.... (metadata: {'creator': 'ChatGPT', 'page_label': '1', 'author': 'ChatGPT Canvas', 'source': 'data/pdf.pdf', 'producer': 'WeasyPrint 65.1', 'page': 0, 'title': 'Smart Water Bottle Proposal', 'total_pages': 3, 'creationdate': ''})\n",
      "Retrieved Document 3 for query 'what is the lenghts of amazon river': potential  due  to  its  unique... (metadata: {'source': 'data/pdf.pdf', 'page_label': '2', 'page': 1, 'creationdate': '', 'producer': 'WeasyPrint 65.1', 'author': 'ChatGPT Canvas', 'creator': 'ChatGPT', 'total_pages': 3, 'title': 'Smart Water Bottle Proposal'})\n"
     ]
    }
   ],
   "source": [
    "query_1=\"who is the information about\"\n",
    "query_2=\"what is the lenghts of amazon river\"\n",
    "\n",
    "retrieved_docs_1 = retriever.invoke(query_1)\n",
    "for i, doc in enumerate(retrieved_docs_1):\n",
    "    print(f\"Retrieved Document {i+1} for query '{query_1}': {doc.page_content[:50]}... (metadata: {doc.metadata})\")\n",
    "\n",
    "print(\"\\n\")\n",
    "retrieved_docs_2 = retriever.invoke(query_2)\n",
    "for i, doc in enumerate(retrieved_docs_2):\n",
    "    print(f\"Retrieved Document {i+1} for query '{query_2}': {doc.page_content[:50]}... (metadata: {doc.metadata})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8b6a30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
