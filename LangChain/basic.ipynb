{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1db5d829",
   "metadata": {},
   "source": [
    "For llm bulk output invoke()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d2c813c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google API Key loaded successfully.\n",
      "Prompt: what is the importance of python in llms architecture\n",
      "Response: Python plays a crucial and multifaceted role in the architecture and development of Large Language Models (LLMs). Its importance stems from its versatility, extensive libraries, and a vibrant community that supports AI and machine learning research. Here's a breakdown of why Python is so critical:\n",
      "\n",
      "**1. Data Preprocessing and Preparation:**\n",
      "\n",
      "*   **Data Wrangling:** LLMs are trained on massive datasets. Python libraries like **Pandas** are indispensable for cleaning, transforming, and preparing this data.  Pandas allows efficient handling of structured data, missing values, and data type conversions.\n",
      "*   **Text Processing:**  Libraries like **NLTK (Natural Language Toolkit)** and **spaCy** provide tools for tokenization, stemming, lemmatization, part-of-speech tagging, and other crucial text processing tasks. These tasks are essential for converting raw text into a format suitable for LLM training.\n",
      "*   **Data Loading and Storage:**  Python facilitates loading data from various sources (files, databases, APIs) and storing processed data efficiently using libraries like **NumPy** (for numerical data) and database connectors (e.g., `psycopg2` for PostgreSQL).\n",
      "\n",
      "**2. Model Development and Training:**\n",
      "\n",
      "*   **Deep Learning Frameworks:** Python is the primary language used with leading deep learning frameworks like **TensorFlow** and **PyTorch**. These frameworks provide the building blocks for defining, training, and evaluating LLMs.\n",
      "*   **Model Implementation:** Python allows researchers and developers to implement complex neural network architectures, including transformers (the core of many LLMs), using TensorFlow or PyTorch.\n",
      "*   **Training Pipelines:** Python scripts are used to orchestrate the entire training process, including data loading, model definition, training loop, validation, and checkpointing.\n",
      "*   **Experimentation and Prototyping:** Python's rapid prototyping capabilities and interactive environments (like Jupyter notebooks) make it ideal for experimenting with different model architectures, hyperparameters, and training strategies.\n",
      "*   **Distributed Training:** Libraries like **Horovod** and frameworks like **PyTorch DistributedDataParallel (DDP)**, accessible via Python, enable distributed training of LLMs across multiple GPUs or machines, which is essential for handling the massive datasets and model sizes involved.\n",
      "\n",
      "**3. Model Evaluation and Monitoring:**\n",
      "\n",
      "*   **Evaluation Metrics:** Python provides tools for calculating various evaluation metrics relevant to LLMs, such as perplexity, BLEU score, ROUGE score, and others.\n",
      "*   **Visualization:**  Libraries like **Matplotlib** and **Seaborn** allow for visualizing model performance, identifying areas for improvement, and tracking training progress.\n",
      "*   **Monitoring and Logging:** Python can be used to implement monitoring systems that track model performance in real-time, detect anomalies, and provide insights into model behavior.\n",
      "\n",
      "**4. Deployment and Inference:**\n",
      "\n",
      "*   **API Development:** Python frameworks like **Flask** and **FastAPI** are commonly used to create APIs that expose LLMs as services. This allows other applications to interact with the model and generate text.\n",
      "*   **Inference Optimization:** Python libraries like **TensorRT** and **ONNX Runtime** can be used to optimize LLMs for faster and more efficient inference.\n",
      "*   **Serving Infrastructure:** Python integrates well with serving infrastructure like **Kubernetes** and **Docker**, enabling scalable and reliable deployment of LLMs.\n",
      "*   **Integration with Other Systems:** Python's versatility allows easy integration of LLMs with other systems and applications, such as chatbots, content creation tools, and search engines.\n",
      "\n",
      "**5. Research and Development:**\n",
      "\n",
      "*   **Community Support:** Python has a large and active community of researchers and developers working on LLMs. This means there are plenty of resources, tutorials, and open-source projects available.\n",
      "*   **Open-Source Ecosystem:** The abundance of open-source libraries and tools in the Python ecosystem accelerates research and development by providing pre-built components and functionalities.\n",
      "*   **Reproducibility:** Python's clear syntax and scripting capabilities promote reproducibility of research results, which is crucial for scientific progress.\n",
      "\n",
      "**In summary, Python is the cornerstone of LLM architecture due to its:**\n",
      "\n",
      "*   **Rich ecosystem of libraries for data processing, model development, and deployment.**\n",
      "*   **Ease of use and rapid prototyping capabilities.**\n",
      "*   **Strong community support and abundant resources.**\n",
      "*   **Integration with leading deep learning frameworks and serving infrastructure.**\n",
      "\n",
      "Without Python, the development, training, and deployment of LLMs would be significantly more challenging and time-consuming.  It's the *lingua franca* of the LLM world.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "\n",
    "load_dotenv()\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(\"Google API Key loaded successfully.\")\n",
    "else:\n",
    "    print(\"Failed to load Google API Key. Please check your .env file.\")\n",
    "    exit()\n",
    "llm= GoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    google_api_key=google_api_key,\n",
    ")\n",
    "\n",
    "prompt=\"what is the importance of python in llms architecture\"\n",
    "\n",
    "print(\"Prompt:\", prompt)\n",
    "response=llm.invoke(prompt)\n",
    "print(\"Response:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fddf7d5",
   "metadata": {},
   "source": [
    "For LLm stream output chunks in llm.stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401be361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python plays a crucial role in the architecture of Large Language Models (LLMs) for several reasons:\n",
      "\n",
      "**1. Data Preprocessing & Preparation:**\n",
      "\n",
      "*   **Data Handling:** LLMs require vast amounts of data for training. Python excels at handling and manipulating large datasets. Libraries like Pandas, NumPy, and Dask are essential for cleaning, transforming, and organizing data from various sources (text, code, etc.).\n",
      "*   **Text Processing:** Python's natural language processing (NLP) libraries like NLTK, SpaCy, and Gensim are widely used for tokenization, stemming, lemmatization, and other text preprocessing tasks crucial for preparing text data for LLM training.\n",
      "*   **Data Augmentation:** Python can be used to implement data augmentation techniques (e.g., paraphrasing, back-translation) to increase the diversity and size of the training dataset, which can improve LLM performance.\n",
      "\n",
      "**2. Model Development & Training:**\n",
      "\n",
      "*   **Frameworks & Libraries:** Python is the primary language for popular deep learning frameworks like TensorFlow and PyTorch, which are heavily used in LLM development and training. These frameworks provide tools for defining neural network architectures, implementing training loops, and optimizing model parameters.\n",
      "*   **Experimentation & Prototyping:** Python's ease of use and vast ecosystem of libraries make it ideal for rapid prototyping and experimentation with different LLM architectures, training techniques, and hyperparameters.\n",
      "*   **Distributed Training:** LLMs often require distributed training across multiple GPUs or machines due to their massive size. Python libraries like Horovod and DeepSpeed, integrated with TensorFlow and PyTorch, facilitate parallel training and optimization.\n",
      "*   **Model Evaluation:** Python is used to evaluate the performance of LLMs using various metrics (e.g., perplexity, BLEU score, ROUGE score) and to identify areas for improvement.\n",
      "\n",
      "**3. Model Deployment & Inference:**\n",
      "\n",
      "*   **Serving LLMs:** Python is commonly used to deploy LLMs as web services or APIs using frameworks like Flask, FastAPI, or Django. This allows other applications to access and utilize the LLM's capabilities.\n",
      "*   **Inference Libraries:** Python libraries like Hugging Face Transformers provide pre-trained LLMs and tools for performing inference efficiently. They handle tasks like tokenization, model loading, and generating predictions.\n",
      "*   **Integration with Other Systems:** Python's versatility makes it easy to integrate LLMs with other systems, such as databases, search engines, and other AI services.\n",
      "\n",
      "**4. Infrastructure & Tooling:**\n",
      "\n",
      "*   **Automation:** Python is used to automate various tasks related to LLM development and deployment, such as data pipeline management, model training, and monitoring.\n",
      "*   **Orchestration:** Tools like Kubernetes, often managed with Python scripts, are used to orchestrate and manage the deployment of LLMs in production environments.\n",
      "*   **Monitoring and Logging:** Python is used to implement monitoring and logging systems to track the performance of LLMs and identify potential issues.\n",
      "\n",
      "**In summary, Python is essential for the entire lifecycle of LLMs, from data preparation to model training, deployment, and maintenance. Its rich ecosystem of libraries, ease of use, and widespread adoption in the machine learning community make it the dominant language for working with LLMs.**\n",
      "\n",
      "Here's a table summarizing the key areas:\n",
      "\n",
      "| Area            | Python Libraries/Tools                               | Importance                                                                                |\n",
      "|-----------------|-------------------------------------------------------|-------------------------------------------------------------------------------------------|\n",
      "| Data Preprocessing | Pandas, NumPy, NLTK, SpaCy, Gensim, Dask               | Handling large datasets, text processing, cleaning, tokenization, data augmentation         |\n",
      "| Model Development | TensorFlow, PyTorch, Transformers, Hugging Face          | Defining architectures, training loops, optimization, pre-trained models                    |\n",
      "| Distributed Training | Horovod, DeepSpeed                                   | Training LLMs across multiple GPUs/machines                                                 |\n",
      "| Model Evaluation | Scikit-learn, Metrics libraries                       | Evaluating performance, identifying areas for improvement                                 |\n",
      "| Deployment & Inference | Flask, FastAPI, Django, Transformers, Hugging Face    | Serving LLMs as APIs, efficient inference, integration with other systems                 |\n",
      "| Infrastructure  | Kubernetes, Python scripting for automation          | Orchestration, managing deployments, automating tasks                                      |\n",
      "| Monitoring      | Various monitoring and logging libraries (e.g., Prometheus) | Tracking performance, identifying issues                                                 |\n",
      "\n",
      "Full Response: Python plays a crucial role in the architecture of Large Language Models (LLMs) for several reasons:\n",
      "\n",
      "**1. Data Preprocessing & Preparation:**\n",
      "\n",
      "*   **Data Handling:** LLMs require vast amounts of data for training. Python excels at handling and manipulating large datasets. Libraries like Pandas, NumPy, and Dask are essential for cleaning, transforming, and organizing data from various sources (text, code, etc.).\n",
      "*   **Text Processing:** Python's natural language processing (NLP) libraries like NLTK, SpaCy, and Gensim are widely used for tokenization, stemming, lemmatization, and other text preprocessing tasks crucial for preparing text data for LLM training.\n",
      "*   **Data Augmentation:** Python can be used to implement data augmentation techniques (e.g., paraphrasing, back-translation) to increase the diversity and size of the training dataset, which can improve LLM performance.\n",
      "\n",
      "**2. Model Development & Training:**\n",
      "\n",
      "*   **Frameworks & Libraries:** Python is the primary language for popular deep learning frameworks like TensorFlow and PyTorch, which are heavily used in LLM development and training. These frameworks provide tools for defining neural network architectures, implementing training loops, and optimizing model parameters.\n",
      "*   **Experimentation & Prototyping:** Python's ease of use and vast ecosystem of libraries make it ideal for rapid prototyping and experimentation with different LLM architectures, training techniques, and hyperparameters.\n",
      "*   **Distributed Training:** LLMs often require distributed training across multiple GPUs or machines due to their massive size. Python libraries like Horovod and DeepSpeed, integrated with TensorFlow and PyTorch, facilitate parallel training and optimization.\n",
      "*   **Model Evaluation:** Python is used to evaluate the performance of LLMs using various metrics (e.g., perplexity, BLEU score, ROUGE score) and to identify areas for improvement.\n",
      "\n",
      "**3. Model Deployment & Inference:**\n",
      "\n",
      "*   **Serving LLMs:** Python is commonly used to deploy LLMs as web services or APIs using frameworks like Flask, FastAPI, or Django. This allows other applications to access and utilize the LLM's capabilities.\n",
      "*   **Inference Libraries:** Python libraries like Hugging Face Transformers provide pre-trained LLMs and tools for performing inference efficiently. They handle tasks like tokenization, model loading, and generating predictions.\n",
      "*   **Integration with Other Systems:** Python's versatility makes it easy to integrate LLMs with other systems, such as databases, search engines, and other AI services.\n",
      "\n",
      "**4. Infrastructure & Tooling:**\n",
      "\n",
      "*   **Automation:** Python is used to automate various tasks related to LLM development and deployment, such as data pipeline management, model training, and monitoring.\n",
      "*   **Orchestration:** Tools like Kubernetes, often managed with Python scripts, are used to orchestrate and manage the deployment of LLMs in production environments.\n",
      "*   **Monitoring and Logging:** Python is used to implement monitoring and logging systems to track the performance of LLMs and identify potential issues.\n",
      "\n",
      "**In summary, Python is essential for the entire lifecycle of LLMs, from data preparation to model training, deployment, and maintenance. Its rich ecosystem of libraries, ease of use, and widespread adoption in the machine learning community make it the dominant language for working with LLMs.**\n",
      "\n",
      "Here's a table summarizing the key areas:\n",
      "\n",
      "| Area            | Python Libraries/Tools                               | Importance                                                                                |\n",
      "|-----------------|-------------------------------------------------------|-------------------------------------------------------------------------------------------|\n",
      "| Data Preprocessing | Pandas, NumPy, NLTK, SpaCy, Gensim, Dask               | Handling large datasets, text processing, cleaning, tokenization, data augmentation         |\n",
      "| Model Development | TensorFlow, PyTorch, Transformers, Hugging Face          | Defining architectures, training loops, optimization, pre-trained models                    |\n",
      "| Distributed Training | Horovod, DeepSpeed                                   | Training LLMs across multiple GPUs/machines                                                 |\n",
      "| Model Evaluation | Scikit-learn, Metrics libraries                       | Evaluating performance, identifying areas for improvement                                 |\n",
      "| Deployment & Inference | Flask, FastAPI, Django, Transformers, Hugging Face    | Serving LLMs as APIs, efficient inference, integration with other systems                 |\n",
      "| Infrastructure  | Kubernetes, Python scripting for automation          | Orchestration, managing deployments, automating tasks                                      |\n",
      "| Monitoring      | Various monitoring and logging libraries (e.g., Prometheus) | Tracking performance, identifying issues                                                 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "full_response=\"\"\n",
    "for chunk in llm.stream(prompt):\n",
    "    print(chunk, end=\"\",flush=True) #print imediately\n",
    "    full_response += chunk\n",
    "print(\"\\nFull Response:\", full_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b39ec9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
